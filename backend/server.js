import express from "express";
import cors from "cors";
import multer from "multer";
import fs from "fs";
import sharp from "sharp";
import fetch from "node-fetch";
import FormData from "form-data";
import { OpenAI } from "openai";

const app = express();
const upload = multer({ dest: "uploads/" });
app.use(cors());
app.use(express.json());

const HF_TOKEN = process.env.OPENAI_API_KEY;
const client = new OpenAI({
  baseURL: "https://router.huggingface.co/v1",
  apiKey: HF_TOKEN,
});

// PaddleOCR í˜¸ì¶œ
async function runOCR(imagePath) {
  const formData = new FormData();
  formData.append("image", fs.createReadStream(imagePath));

  const res = await fetch(OCR_SERVICE_URL, {
    method: "POST",
    body: formData,
  });

  if (!res.ok) {
    console.error("OCR API ì˜¤ë¥˜:", res.status, await res.text());
    return { texts: [], joined: "" };
  }

  const data = await res.json();
  return {
    texts: data.ocr_texts || [],
    joined: data.ocr_text_joined || ""
  };
}

// Qwen ë©€í‹°ëª¨ë‹¬ í˜¸ì¶œ
async function runVLModel(imagePath, ocrText) {
  const resizedBuffer = await sharp(imagePath)
    .resize({ width: 512 })
    .jpeg({ quality: 80 })
    .toBuffer();

  const base64Image = `data:image/jpeg;base64,${resizedBuffer.toString("base64")}`;

  const messages = [
    {
      role: "user",
      content: [
        {
          type: "text",
          text: ocrText
            ? `ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸: "${ocrText}". ì´ë¥¼ ì°¸ê³ í•˜ì—¬ ìž¥ë©´ê³¼ ì¡°í•©í•´ Alt tagë¥¼ 100ìž ë‚´ì™¸ë¡œ ìƒì„±í•´ ì£¼ì„¸ìš”.`
            : "ì´ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•˜ëŠ” Alt tagë¥¼ 100ìž ë‚´ì™¸ë¡œ ìƒì„±í•´ ì£¼ì„¸ìš”.",
        },
        { type: "image_url", image_url: { url: base64Image } },
      ],
    },
  ];

  const chatCompletion = await client.chat.completions.create({
    model: "Qwen/Qwen2.5-VL-7B-Instruct:hyperbolic",
    messages,
  });

  return chatCompletion.choices[0].message.content || "Alt tag ìƒì„± ì‹¤íŒ¨";
}

// Alt tag API ì—”ë“œí¬ì¸íŠ¸
app.post("/api/generate-alt", upload.single("image"), async (req, res) => {
  try {
    const { texts, joined } = await runOCR(req.file.path);
    const altTag = await runVLModel(req.file.path, joined);
    fs.unlinkSync(req.file.path);
    res.json({ altTag, ocrTexts: texts });
  } catch (err) {
    console.error(err);
    res.status(500).json({ error: "Alt tag ìƒì„± ì‹¤íŒ¨" });
  }
});

const PORT = process.env.PORT || 3000;
app.listen(PORT, () => console.log(`ðŸš€ PaddleOCR+Qwen backend running on port ${PORT}`));